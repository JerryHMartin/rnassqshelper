---
title: "monthly-county-cotton-yield"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{monthly-county-cotton-yield}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}

# --- Setup ---
library(rnassqshelper)

# States to query
cotton_states <- c(
  "CALIFORNIA", "ARIZONA", "NEW MEXICO", "OKLAHOMA", "TEXAS",
  "KANSAS", "LOUISIANA", "MISSOURI", "ARKANSAS", "MISSISSIPPI",
  "TENNESSEE", "ALABAMA", "FLORIDA", "NORTH CAROLINA", "GEORGIA",
  "VIRGINIA", "SOUTH CAROLINA"
)

# # --- Auth: get/set NASS key ---
# api_key <- tryCatch(
#   rnassqshelper:::get_nass_key(),
#   error = function(e) Sys.getenv("NASS_API_KEY", "")
# )
# if (!nzchar(api_key)) stop("No NASS_API_KEY found. Add it to .Renviron or use rnassqshelper:::get_nass_key().")
# rnassqs::nassqs_auth(key = api_key)


# --- Auth: get/set NASS key ---
api_key <- rnassqshelper::ensure_nass_key(persist = "session")



# --- Build grid and fetch using the new wrapper ---
#years <- 1970:2025
years <- 2025

# Directly call get_nass_yield() with vectors of states and years.
# This returns a single tibble (by default) with all results.
raw_data <- get_nass_yield(
  state      = cotton_states,
  year       = years,
  commodity  = "COTTON",
  statistic  = "YIELD",
  agg_level  = "COUNTY",
  freq       = "MONTHLY",
  sleep      = 0.25
  # If you want a base data.frame instead of a tibble:
  # as_tibble = FALSE
)

# Quick peek
message("Total rows fetched: ", nrow(raw_data))
print(utils::head(raw_data))

# --- Normalize names and clean text ---
normalize_names <- function(df) {
  nms <- tolower(names(df))
  nms <- gsub("[^a-z0-9]+", "_", nms)   # spaces/slashes -> underscore
  names(df) <- nms
  df
}

cleaned <- raw_data |>
  normalize_names() |>
  dplyr::mutate(across(where(is.character), ~ trimws(.x)))



library(dplyr)
library(openxlsx)

# Create workbook
wb <- createWorkbook()

# Ensure we have a 'state' column to split by (adjust if your column is named differently)
if (!"state" %in% names(cleaned)) {
  stop("The 'cleaned' dataset must include a 'state' column to build per-state sheets.")
}

# Excel's per-sheet row limit
excel_limit <- 1048576L

# Simple header style
hdr_style <- createStyle(textDecoration = "bold", fgFill = "#EFEFEF", halign = "left")

# Split and add each state as a worksheet
by_state <- split(cleaned, cleaned$state)

for (st in names(by_state)) {
  df <- by_state[[st]]

  # Excel sheet names must be <= 31 chars and avoid: []:*?/\
  safe_name <- gsub("[\\[\\]\\:\\*\\?\\/\\\\]", "-", st)
  safe_name <- substr(safe_name, 1, 31)

  addWorksheet(wb, sheetName = safe_name)

  # If the state's data exceeds Excel's row limit, write the first chunk and warn
  if (nrow(df) > excel_limit) {
    warning(sprintf("State '%s' has %s rows; truncating to %s for Excel. Consider splitting.",
                    st, nrow(df), excel_limit))
    df <- df[seq_len(excel_limit), , drop = FALSE]
  }

  writeData(wb, sheet = safe_name, x = df, withFilter = TRUE, headerStyle = hdr_style)
  freezePane(wb, sheet = safe_name, firstRow = TRUE)

  # Auto column widths (cap the maximum width so Excel stays readable)
  col_widths <- pmin(30, sapply(df, function(col) max(nchar(as.character(col)), na.rm = TRUE)))
  setColWidths(wb, sheet = safe_name, cols = seq_along(col_widths), widths = col_widths)
}

# Build a timestamped filename
ts <- format(Sys.time(), "%Y%m%d_%H%M%S")
xlsx_file <- sprintf("cotton_yield_by_state_%s.xlsx", ts)

saveWorkbook(wb, file = xlsx_file, overwrite = TRUE)

message("Saved per-state workbook to: ", normalizePath(xlsx_file))


```
